# cep146-project1
This is our group's repository for project-software-development in cep146.
Our topic is about **the ethics of AI in software development**.

Rubric and project outline: https://github.com/seneca-cep146/cep146/blob/main/project/project-software-development.md

---

## Group members:
- Victer Yoo
- Minh Tuan Ho
- Cozmo Walker



AI Ethics in Software Development (2025)
1. Introduction

Hello everyone, today our topic is AI Ethics in Software Development.

It’s 2025, and Artificial Intelligence has become a major part of how we build software.
Tools like ChatGPT, GitHub Copilot, and DeepSeek can generate code, suggest fixes, and help developers work faster.
AI clearly boosts productivity — but it also brings serious ethical concerns, including bias, privacy, copyright, and accountability.

[](https://apnews.com/article/business-apple-inc-artificial-intelligence-00c1dab0a727456df9e5ef9c6160c792)

2. The Google AI Ethics Controversy

A well-known example is the Google AI ethics controversy.
Researcher Timnit Gebru was forced to leave Google after publishing a paper about the ethical risks of large language models.
Her paper discussed bias and fairness in data, and the lack of transparency and accountability.
She warned that AI systems might reinforce stereotypes or spread misinformation — which could impact the fairness and reliability of software created with AI assistance.

3. Bias and Fairness

AI systems learn from data collected across the internet.
However, online data often includes biased or unfair patterns, such as stereotypes or unbalanced language.
When AI learns from that data, it may reproduce those same biases — leading to unfair or harmful code suggestions.
For example, biased code or variable names could appear without the developer realizing it.
This raises a key question: Can we fully trust AI-generated code if its training data already contains bias?

4. Privacy 

Large language models are trained on massive datasets, sometimes including private or copyrighted materials.
People might not even know their information was used in training.
This leads to privacy concerns about data protection and consent.

5. Copyright
At the same time, copyright becomes a serious issue.
AI systems often learn from existing online text, code, or art without asking for permission.
So when AI generates new outputs, it might accidentally reuse parts of someone else’s work — raising questions about ownership and originality.

6. Accountability and Transparency

Finally, we face the problem of accountability.
If AI-generated code causes harm — such as bugs, security flaws, or misinformation — who is responsible?
Is it the developer who used the AI, the company that built it, or the AI system itself?
Currently, there’s no clear answer.

In conclusion, AI is transforming software development by making it faster and smarter, but it also challenges us to think carefully about ethics, fairness, and transparency.

Final Question:

If we use AI tools and they generate code that causes harm, who should be responsible — the developer, the company that built the AI, or the AI system itself?
 

Final questions 
If we use AI tools and it generates codes that causes harm who should be responsible? The developers? The company who built the ai? 
